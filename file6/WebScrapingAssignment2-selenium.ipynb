{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad12c6db",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment 2 (Using Selenium)\n",
    "\n",
    "# By Olayemi Morrison\n",
    "\n",
    "# Project: Batch DS2306"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47d505",
   "metadata": {},
   "source": [
    "#### Q1: Write a python program to scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "\n",
    "#### This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúSkill, Designations, Companies‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01268ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fe10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome driver\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5dda085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21c0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering location\n",
    "location=driver.find_element(By.XPATH, \"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d1700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the search button\n",
    "search=driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6d5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "# scraping job title from web page\n",
    "title_tags=driver.find_elements(By.XPATH, \"//a[@class='title ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "\n",
    "\n",
    "# scraping job location from web page\n",
    "location_tags=driver.find_elements(By.XPATH, \"//span[@class='ellipsis fleft locWdth']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "\n",
    "\n",
    "# scraping company name from web page\n",
    "company_tags=driver.find_elements(By.XPATH, \"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# scraping experience from web page\n",
    "experience_tags=driver.find_elements(By.XPATH, \"//span[@class='ellipsis fleft expwdth']\")\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ce69c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381f4357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Eastvantage</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka, Gurgaon/ Guru...</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HCL hiring For GCP Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka, Hyderabad/ Se...</td>\n",
       "      <td>HCLTech</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Everest Vacuum</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst, RSO</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Pluralsight</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Boomi Software</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune</td>\n",
       "      <td>Synechron</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune</td>\n",
       "      <td>Synchron Infotech</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Persolkelly India</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  \\\n",
       "0                     Data Analyst   \n",
       "1                     Data Analyst   \n",
       "2  HCL hiring For GCP Data Analyst   \n",
       "3                     Data Analyst   \n",
       "4                Data Analyst, RSO   \n",
       "5                     Data Analyst   \n",
       "6                     Data Analyst   \n",
       "7                     Data Analyst   \n",
       "8                   Data Analyst I   \n",
       "9                     Data Analyst   \n",
       "\n",
       "                                            Location       Company_name  \\\n",
       "0                                Bangalore/Bengaluru        Eastvantage   \n",
       "1  Bangalore/ Bengaluru, Karnataka, Gurgaon/ Guru...          Delhivery   \n",
       "2  Bangalore/ Bengaluru, Karnataka, Hyderabad/ Se...            HCLTech   \n",
       "3                                Bangalore/Bengaluru     Everest Vacuum   \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...        Pluralsight   \n",
       "5  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...     Boomi Software   \n",
       "6  Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune          Synechron   \n",
       "7  Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune  Synchron Infotech   \n",
       "8                                Bangalore/Bengaluru             Cerner   \n",
       "9                                Bangalore/Bengaluru  Persolkelly India   \n",
       "\n",
       "  Experience  \n",
       "0    4-6 Yrs  \n",
       "1    1-3 Yrs  \n",
       "2   5-10 Yrs  \n",
       "3    2-5 Yrs  \n",
       "4    1-4 Yrs  \n",
       "5    1-5 Yrs  \n",
       "6    5-8 Yrs  \n",
       "7    5-8 Yrs  \n",
       "8   5-10 Yrs  \n",
       "9    0-2 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcc7de",
   "metadata": {},
   "source": [
    "#### Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "#### This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, Companies‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba9b065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome driver\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e3cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b345599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the location\n",
    "\n",
    "location=driver.find_element(By.XPATH, \"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91fca518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click the search button\n",
    "search=driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a83ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title2=[]\n",
    "job_location2=[]\n",
    "company_name2=[]\n",
    "experience_required2=[]\n",
    "\n",
    "# scraping job title from web page\n",
    "title_tags=driver.find_elements(By.XPATH, \"//a[@class='title ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title2.append(title)\n",
    "    \n",
    "\n",
    "\n",
    "# scraping job location from web page\n",
    "location_tags=driver.find_elements(By.XPATH, \"//span[@class='ellipsis fleft locWdth']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location2.append(location)\n",
    "\n",
    "\n",
    "\n",
    "# scraping company name from web page\n",
    "company_tags=driver.find_elements(By.XPATH, \"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name2.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# scraping experience from web page\n",
    "experience_tags=driver.find_elements(By.XPATH, \"//span[@class='ellipsis fleft expwdth']\")\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required2.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a22c286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title2),len(job_location2),len(company_name2),len(experience_required2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d38e2708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>PwC</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Lead</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Pluralsight</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Tredence</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>IBS Software Services</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Noid...</td>\n",
       "      <td>HCLTech</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist with Retail Domain</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Nagpur, ...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1                            Data Science Specialist   \n",
       "2                                     Data Scientist   \n",
       "3                                Data Scientist Lead   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6  ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "7                              Senior Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                  Data Scientist with Retail Domain   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "5  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "6  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...   \n",
       "7                        Bangalore/Bengaluru, Mumbai   \n",
       "8  Hybrid - Bangalore/ Bengaluru, Karnataka, Noid...   \n",
       "9  Bangalore/Bengaluru, Kolkata, Mumbai, Nagpur, ...   \n",
       "\n",
       "               Company_name Experience  \n",
       "0                 Accenture    6-8 Yrs  \n",
       "1                 Accenture    2-4 Yrs  \n",
       "2                       PwC    3-6 Yrs  \n",
       "3               Pluralsight   8-13 Yrs  \n",
       "4                  Tredence    2-4 Yrs  \n",
       "5     IBS Software Services    5-8 Yrs  \n",
       "6                 Accenture    2-7 Yrs  \n",
       "7         Fractal Analytics   5-10 Yrs  \n",
       "8                   HCLTech   7-12 Yrs  \n",
       "9  TRH Consultancy Services    4-9 Yrs  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title2,'Location':job_location2,'Company_name':company_name2,'Experience':experience_required2})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d6c7e",
   "metadata": {},
   "source": [
    "#### Q3: In this question you have to scrape data using the filters available on the webpage as shown below\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7471233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome driver\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "573f2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and loacation\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f0a50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d41a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the location filter\n",
    "location=driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "962d4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the salary filter\n",
    "salary=driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79e5afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title3=[]\n",
    "job_location3=[]\n",
    "company_name3=[]\n",
    "experience_required3=[]\n",
    "\n",
    "# scraping job title from web page\n",
    "title_tags=driver.find_elements(By.XPATH, \"//a[@class='title ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title3.append(title)\n",
    "    \n",
    "\n",
    "\n",
    "# scraping job location from web page\n",
    "location_tags=driver.find_elements(By.XPATH, \"//span[@class='ellipsis fleft locWdth']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location3.append(location)\n",
    "\n",
    "\n",
    "\n",
    "# scraping company name from web page\n",
    "company_tags=driver.find_elements(By.XPATH, \"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name3.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# scraping experience from web page\n",
    "experience_tags=driver.find_elements(By.XPATH, \"//span[@class='ellipsis fleft expwdth']\")\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required3.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dfa6b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title3),len(job_location3),len(company_name3),len(experience_required3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6776f1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist/ Manager...</td>\n",
       "      <td>Noida, Kolkata, Mumbai, Chandigarh, Hyderabad/...</td>\n",
       "      <td>Dreambig It Solutions India</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python and ML Trainer</td>\n",
       "      <td>Hyderabad/Secunderabad, New Delhi, Pune, Gurga...</td>\n",
       "      <td>Thescholar</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>SquadRun, Inc</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Scientist - ML &amp; NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Gartner</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                              Junior Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2  Data Scientist/ Senior Data Scientist/ Manager...   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                              Python and ML Trainer   \n",
       "6                          Hiring For Data Scientist   \n",
       "7                              Junior Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                Associate Data Scientist - ML & NLP   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "1              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2  Noida, Kolkata, Mumbai, Chandigarh, Hyderabad/...   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4                                              Noida   \n",
       "5  Hyderabad/Secunderabad, New Delhi, Pune, Gurga...   \n",
       "6                                             Remote   \n",
       "7    Gurgaon/Gurugram, United States (USA), Bulgaria   \n",
       "8                                              Noida   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                  Company_name Experience  \n",
       "0                     Analytos    0-2 Yrs  \n",
       "1                    Blackbuck    3-7 Yrs  \n",
       "2  Dreambig It Solutions India    1-6 Yrs  \n",
       "3                     Analytos    2-4 Yrs  \n",
       "4               Times Internet    3-8 Yrs  \n",
       "5                   Thescholar    3-8 Yrs  \n",
       "6                     Infogain    4-9 Yrs  \n",
       "7                       Adidas    1-6 Yrs  \n",
       "8                SquadRun, Inc    1-4 Yrs  \n",
       "9                      Gartner    2-4 Yrs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title3,'Location':job_location3,'Company_name':company_name3,'Experience':experience_required3})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec596dbc",
   "metadata": {},
   "source": [
    "#### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "#### The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter ‚Äúsunglasses‚Äù in the search field where ‚Äúsearch for products, brands and more‚Äù is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the ‚ÄúNext‚Äù Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f40b9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page on automated chrome driver\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb4045f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering sunglasses in the search field\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"Pke_EE\")\n",
    "search.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a761d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button\n",
    "search_btn=driver.find_element(By.CLASS_NAME, \"_2iLD__\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5b5eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping sunglasses data for brand, product price\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "\n",
    "start=0\n",
    "end=3       #to scrape data from the first 3 pages\n",
    "for page in range(start,end):\n",
    "    brand_name=driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_name:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    description=driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for i in description:\n",
    "        product_desc.append(i.text)\n",
    "    \n",
    "    prc=driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for i in prc:\n",
    "        price.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cad1c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 115 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(product_desc),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d84172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAKLEY</td>\n",
       "      <td>HOLBROOK Wayfarer Sunglass</td>\n",
       "      <td>‚Çπ4,981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VOLRIX</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>‚Çπ194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>‚Çπ168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>‚Çπ949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ1,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Shiv</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>‚Çπ249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>‚Çπ256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product_Description   Price\n",
       "0          OAKLEY                         HOLBROOK Wayfarer Sunglass  ‚Çπ4,981\n",
       "1          VOLRIX   UV Protection Rectangular Sunglasses (Free Size)    ‚Çπ263\n",
       "2            SRPM             UV Protection Wayfarer Sunglasses (50)    ‚Çπ194\n",
       "3        Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ‚Çπ675\n",
       "4       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...    ‚Çπ168\n",
       "..            ...                                                ...     ...\n",
       "95           SRPM  UV Protection Retro Square Sunglasses (Free Size)    ‚Çπ194\n",
       "96  VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)    ‚Çπ949\n",
       "97  VINCENT CHASE  UV Protection Retro Square Sunglasses (Free Size)  ‚Çπ1,049\n",
       "98           Shiv             UV Protection Wayfarer Sunglasses (53)    ‚Çπ249\n",
       "99        ROADWAY                UV Protection Round Sunglasses (50)    ‚Çπ256\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':brand[0:100],'Product_Description':product_desc[0:100],'Price':price[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c23bd3",
   "metadata": {},
   "source": [
    "#### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7908f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page on automated chrome driver\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69cf4499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping iphone data for rating, review summary & full review\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "start=0\n",
    "end=10     #to scrape data from the first 10 pages\n",
    "for page in range(start,end):\n",
    "    rating_tag=driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tag:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "    review_tag=driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tag:\n",
    "        review_summary.append(i.text)\n",
    "    \n",
    "    f_review=driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "    for i in f_review:\n",
    "        full_review.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c55652e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6edcf3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Perfect Product!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent Phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money üñ§üñ§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>It‚Äôs very good battery life and display and vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I dreamt about this day from a long time.... G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Very good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review_Summary  \\\n",
       "0       5         Classy product   \n",
       "1       5  Mind-blowing purchase   \n",
       "2       5              Wonderful   \n",
       "3       5               Terrific   \n",
       "4       5              Just wow!   \n",
       "..    ...                    ...   \n",
       "95      5              Brilliant   \n",
       "96      5      Terrific purchase   \n",
       "97      5              Fabulous!   \n",
       "98      5                Awesome   \n",
       "99      5              Wonderful   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "1                                        Photos super  \n",
       "2                              This is amazing at all  \n",
       "3                                      Very very good  \n",
       "4                                   Perfect Product!!  \n",
       "..                                                ...  \n",
       "95                                   Excellent Phone.  \n",
       "96                                 Value for money üñ§üñ§  \n",
       "97  It‚Äôs very good battery life and display and vi...  \n",
       "98  I dreamt about this day from a long time.... G...  \n",
       "99                                          Very good  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Rating':rating,'Review_Summary':review_summary,'Full_Review':full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401e1e1",
   "metadata": {},
   "source": [
    "#### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1b42efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page on automated chrome driver\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee5bafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering sneakers in the search field\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"Pke_EE\")\n",
    "search.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff94f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button\n",
    "search_btn=driver.find_element(By.CLASS_NAME, \"_2iLD__\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d03b4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping sneakers data for brand, product price\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "\n",
    "start=0\n",
    "end=3    #to scrape data from the first 3 pages\n",
    "for page in range(start,end):\n",
    "    brand_name=driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_name:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    description=driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for i in description:\n",
    "        product_desc.append(i.text)\n",
    "    \n",
    "    prc=driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for i in prc:\n",
    "        price.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "019e1ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 111 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(product_desc),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a5c13b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium Sports Shoes For Men Pack Of 2 Sneaker...</td>\n",
       "      <td>‚Çπ479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K- FOOTLANCE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Modern Trendy Sneakers boot Sneakers Sneakers ...</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>‚Çπ389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>asian</td>\n",
       "      <td>Hustle V2 Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>K- FOOTLANCE</td>\n",
       "      <td>Hustle V2 Sneakers For Men</td>\n",
       "      <td>‚Çπ449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>‚Çπ1,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kzaara</td>\n",
       "      <td>Fashion and Stylish Soft Ultralight Lace Up Sn...</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nobelite</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product_Description   Price\n",
       "0          BIRDE  Premium Sports Shoes For Men Pack Of 2 Sneaker...    ‚Çπ479\n",
       "1   K- FOOTLANCE                                   Sneakers For Men    ‚Çπ449\n",
       "2       Magnolia  Modern Trendy Sneakers boot Sneakers Sneakers ...    ‚Çπ499\n",
       "3         BRUTON               Modern Trendy Shoes Sneakers For Men    ‚Çπ299\n",
       "4           aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ‚Çπ389\n",
       "..           ...                                                ...     ...\n",
       "95         asian                         Hustle V2 Sneakers For Men    ‚Çπ499\n",
       "96  K- FOOTLANCE                         Hustle V2 Sneakers For Men    ‚Çπ449\n",
       "97          ATOM                                 Sneakers For Women  ‚Çπ1,389\n",
       "98        Kzaara  Fashion and Stylish Soft Ultralight Lace Up Sn...    ‚Çπ499\n",
       "99      Nobelite                                   Sneakers For Men    ‚Çπ469\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':brand[0:100],'Product_Description':product_desc[0:100],'Price':price[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad890dd",
   "metadata": {},
   "source": [
    "#### Q7: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then set CPU Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image:\n",
    "    \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf93684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the amazon page on automated chrome driver\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f8a330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering laptop in the search field\n",
    "\n",
    "search=driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "search.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "108718b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button\n",
    "search_btn=driver.find_element(By.ID, \"nav-search-submit-button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e84e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the CPU Type filter\n",
    "CPU_Type=driver.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[7]/span[10]/li/span/a/span\")\n",
    "CPU_Type.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41247d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping laptop data for title, rating & price\n",
    "title=[]\n",
    "ratings=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title.append(i.text)\n",
    "        \n",
    "rating_tags=driver.find_elements(By.XPATH, '//span[@class=\"a-icon-alt\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "price_tags=driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebc2ffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(ratings),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "543d3330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Aspire 3 Intel Core i5 12th Generation (1...</td>\n",
       "      <td></td>\n",
       "      <td>51,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Aspire Lite 11th Gen Intel Core i5-1155G7...</td>\n",
       "      <td></td>\n",
       "      <td>42,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(8 GB RAM/512GB SSD/Intel Iris Xe Graphics, Wi...</td>\n",
       "      <td></td>\n",
       "      <td>50,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi Notebook Pro Max 11th Gen Intel Core i5...</td>\n",
       "      <td></td>\n",
       "      <td>68,480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP</td>\n",
       "      <td></td>\n",
       "      <td>67,740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15, 13th Gen Intel Core i5-1335U, 15.6-inch (3...</td>\n",
       "      <td></td>\n",
       "      <td>71,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Inspiron 5430 13th Gen</td>\n",
       "      <td></td>\n",
       "      <td>71,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>, Intel Core i5-1335U/8GB/1TB SSD/14.0\" (35.56...</td>\n",
       "      <td></td>\n",
       "      <td>60,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Aspire Lite 11th Gen Intel Core i5-1155G7...</td>\n",
       "      <td></td>\n",
       "      <td>70,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(16GB RAM/512GB SSD/Intel Iris Xe Graphics, Wi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings   Price\n",
       "0  Acer Aspire 3 Intel Core i5 12th Generation (1...          51,990\n",
       "1  Acer Aspire Lite 11th Gen Intel Core i5-1155G7...          42,990\n",
       "2  (8 GB RAM/512GB SSD/Intel Iris Xe Graphics, Wi...          50,999\n",
       "3  Xiaomi Notebook Pro Max 11th Gen Intel Core i5...          68,480\n",
       "4                                                 HP          67,740\n",
       "5  15, 13th Gen Intel Core i5-1335U, 15.6-inch (3...          71,990\n",
       "6                        Dell Inspiron 5430 13th Gen          71,990\n",
       "7  , Intel Core i5-1335U/8GB/1TB SSD/14.0\" (35.56...          60,990\n",
       "8  Acer Aspire Lite 11th Gen Intel Core i5-1155G7...          70,990\n",
       "9  (16GB RAM/512GB SSD/Intel Iris Xe Graphics, Wi...                "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':title,'Ratings':ratings,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab35b35",
   "metadata": {},
   "source": [
    "#### Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpage https://www.azquotes.com/\n",
    "2. Click on Top Quotes\n",
    "3. Then scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02bf2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the azquotes page on automated chrome driver\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e47f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Top Quotes\n",
    "top_quote=driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "top_quote.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e9a6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping quotes data\n",
    "quote=[]\n",
    "author=[]\n",
    "quote_type=[]\n",
    "\n",
    "start=0\n",
    "end=10 #to scrape data from the first 10 pages\n",
    "for page in range(start,end):\n",
    "    quote_tags=driver.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "    author_tags=driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "    \n",
    "    type_tags=driver.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        quote_type.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[4]/li[12]/a\")\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ca71e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(quote),len(author),len(quote_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "403b4582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type_of_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                Type_of_quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Quote':quote,'Author':author,'Type_of_quote':quote_type})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829bef82",
   "metadata": {},
   "source": [
    "#### Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f455dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the jagranjosh page on automated chrome driver\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f99d2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on GK\n",
    "gk=driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a\")\n",
    "gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17a501be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on prime ministers\n",
    "prime_ministers=driver.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "prime_ministers.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebb8b20e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSelectorException",
     "evalue": "Message: invalid selector: An invalid or illegal selector was specified\n  (Session info: chrome=115.0.5790.99); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalid-selector-exception\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x011AA813+48355]\n\t(No symbol) [0x0113C4B1]\n\t(No symbol) [0x01045358]\n\t(No symbol) [0x010487A1]\n\t(No symbol) [0x010499E1]\n\t(No symbol) [0x01049A80]\n\t(No symbol) [0x0107061C]\n\t(No symbol) [0x01070B3B]\n\t(No symbol) [0x0109E26C]\n\t(No symbol) [0x0108A784]\n\t(No symbol) [0x0109C922]\n\t(No symbol) [0x0108A536]\n\t(No symbol) [0x010682DC]\n\t(No symbol) [0x010693DD]\n\tGetHandleVerifier [0x0140AABD+2539405]\n\tGetHandleVerifier [0x0144A78F+2800735]\n\tGetHandleVerifier [0x0144456C+2775612]\n\tGetHandleVerifier [0x012351E0+616112]\n\t(No symbol) [0x01145F8C]\n\t(No symbol) [0x01142328]\n\t(No symbol) [0x0114240B]\n\t(No symbol) [0x01134FF7]\n\tBaseThreadInitThunk [0x76897D59+25]\n\tRtlInitializeExceptionChain [0x7795B79B+107]\n\tRtlClearBits [0x7795B71F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11544\\2719980738.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#scrape prime ministers data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprime_ministers_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//*[@id='itemdiv']/div[4]/span/div[3]/table/tbody\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTAG_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'td'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m: Message: invalid selector: An invalid or illegal selector was specified\n  (Session info: chrome=115.0.5790.99); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalid-selector-exception\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x011AA813+48355]\n\t(No symbol) [0x0113C4B1]\n\t(No symbol) [0x01045358]\n\t(No symbol) [0x010487A1]\n\t(No symbol) [0x010499E1]\n\t(No symbol) [0x01049A80]\n\t(No symbol) [0x0107061C]\n\t(No symbol) [0x01070B3B]\n\t(No symbol) [0x0109E26C]\n\t(No symbol) [0x0108A784]\n\t(No symbol) [0x0109C922]\n\t(No symbol) [0x0108A536]\n\t(No symbol) [0x010682DC]\n\t(No symbol) [0x010693DD]\n\tGetHandleVerifier [0x0140AABD+2539405]\n\tGetHandleVerifier [0x0144A78F+2800735]\n\tGetHandleVerifier [0x0144456C+2775612]\n\tGetHandleVerifier [0x012351E0+616112]\n\t(No symbol) [0x01145F8C]\n\t(No symbol) [0x01142328]\n\t(No symbol) [0x0114240B]\n\t(No symbol) [0x01134FF7]\n\tBaseThreadInitThunk [0x76897D59+25]\n\tRtlInitializeExceptionChain [0x7795B79B+107]\n\tRtlClearBits [0x7795B71F+191]\n"
     ]
    }
   ],
   "source": [
    "#scrape prime ministers data\n",
    "prime_ministers_data=[]\n",
    "table = driver.find_elements(By.CLASS_NAME, \"//*[@id='itemdiv']/div[4]/span/div[3]/table/tbody\")\n",
    "for row in table:\n",
    "    columns = row.find_elements(By.TAG_NAME, 'td')\n",
    "    for column in columns:\n",
    "        name = columns[1].text.strip()\n",
    "        born_dead = columns[2].text.strip()\n",
    "        term_of_office = columns[3].text.strip()\n",
    "        remarks = columns[4].text.strip()\n",
    "\n",
    "    prime_ministers_data.append({\n",
    "            'Name': name,\n",
    "            'Born-Dead': born_dead,\n",
    "            'Term of Office': term_of_office,\n",
    "            'Remarks': remarks\n",
    "        })\n",
    "\n",
    "prime_ministers_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a49e6",
   "metadata": {},
   "source": [
    "#### Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ‚Äô50 most expensive cars‚Äô\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f70cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the motor1 page on automated chrome driver\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11138688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering 50 most expensive cars in the search field\n",
    "\n",
    "search=driver.find_element(By.ID,\"search_input\")\n",
    "search.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca185908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button\n",
    "search_btn=driver.find_element(By.XPATH, \"/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/button[1]\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c2bdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "article=driver.find_element(By.XPATH, \"/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a\")\n",
    "article.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75e3ee05",
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: stale element not found\n  (Session info: chrome=115.0.5790.99); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x011AA813+48355]\n\t(No symbol) [0x0113C4B1]\n\t(No symbol) [0x01045358]\n\t(No symbol) [0x0104E5A3]\n\t(No symbol) [0x01048A78]\n\t(No symbol) [0x01047C03]\n\t(No symbol) [0x010499E1]\n\t(No symbol) [0x01049A80]\n\t(No symbol) [0x0106D2FD]\n\t(No symbol) [0x0108A73C]\n\t(No symbol) [0x01069A36]\n\t(No symbol) [0x0108AA94]\n\t(No symbol) [0x0109C922]\n\t(No symbol) [0x0108A536]\n\t(No symbol) [0x010682DC]\n\t(No symbol) [0x010693DD]\n\tGetHandleVerifier [0x0140AABD+2539405]\n\tGetHandleVerifier [0x0144A78F+2800735]\n\tGetHandleVerifier [0x0144456C+2775612]\n\tGetHandleVerifier [0x012351E0+616112]\n\t(No symbol) [0x01145F8C]\n\t(No symbol) [0x01142328]\n\t(No symbol) [0x0114240B]\n\t(No symbol) [0x01134FF7]\n\tBaseThreadInitThunk [0x76897D59+25]\n\tRtlInitializeExceptionChain [0x7795B79B+107]\n\tRtlClearBits [0x7795B71F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11544\\2640684385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprice_tags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//span[@class='ellipsis fleft locWdth']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocation_tags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mjob_location3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: stale element not found\n  (Session info: chrome=115.0.5790.99); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x011AA813+48355]\n\t(No symbol) [0x0113C4B1]\n\t(No symbol) [0x01045358]\n\t(No symbol) [0x0104E5A3]\n\t(No symbol) [0x01048A78]\n\t(No symbol) [0x01047C03]\n\t(No symbol) [0x010499E1]\n\t(No symbol) [0x01049A80]\n\t(No symbol) [0x0106D2FD]\n\t(No symbol) [0x0108A73C]\n\t(No symbol) [0x01069A36]\n\t(No symbol) [0x0108AA94]\n\t(No symbol) [0x0109C922]\n\t(No symbol) [0x0108A536]\n\t(No symbol) [0x010682DC]\n\t(No symbol) [0x010693DD]\n\tGetHandleVerifier [0x0140AABD+2539405]\n\tGetHandleVerifier [0x0144A78F+2800735]\n\tGetHandleVerifier [0x0144456C+2775612]\n\tGetHandleVerifier [0x012351E0+616112]\n\t(No symbol) [0x01145F8C]\n\t(No symbol) [0x01142328]\n\t(No symbol) [0x0114240B]\n\t(No symbol) [0x01134FF7]\n\tBaseThreadInitThunk [0x76897D59+25]\n\tRtlInitializeExceptionChain [0x7795B79B+107]\n\tRtlClearBits [0x7795B71F+191]\n"
     ]
    }
   ],
   "source": [
    "car_name=[]\n",
    "Price=[]\n",
    "\n",
    "# scraping car name from web page\n",
    "name_tags=driver.find_elements(By.XPATH, \"//h3[@class='subheader']\")\n",
    "for i in name_tags:\n",
    "    car_name.append(i.text)\n",
    "\n",
    "\n",
    "# scraping price from web page\n",
    "price_tags=driver.find_elements(By.XPATH, \"//span[@class='ellipsis fleft locWdth']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location3.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f514b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
